---
title: "Analysis of GLMs with missing covariate values using JointAI"
author: "Nicole Erler"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Linear Regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
<!-- For now, we will work with the complete cases only. -->
<!-- ```{r} -->
<!-- pbc.cc <- subset(pbc, complete.cases(pbc)) -->
<!-- ``` -->


## Analysis model
**JointAI** has three main functions:

* `lm_imp()` (linear regression)
* `glm_imp()` (generalized linear regression)
* `lme_imp()` (linear mixed effects regression)

`glm_imp()` requires the specification of a family and link (analogue to `glm()`).^[
<span style = "color:red"> has to be specified as `family = binomial(link = "logit")`.
`family = "binomial"` or `family  = binomial()` (which work for `glm()`) are not implemented.</span>]
In the current implementation, the families `binomial`, `gaussian`, `Gamma` and `poisson`,
and link functions `identity`, `inverse`, `logit`, `probit`, `log`, and `cloglog` are
available.

## Example: Binary regression
### Data: `pbc`
We will use the `pbc` data from the package `survival` for illustration.
Since several of the categorical variables are specified as integer values, we re-code
all variables with less than 6 different values as factors.
```{r}
library(survival)
for (i in 1:ncol(pbc)){
  if (length(unique(pbc[, i])) < 6){
    pbc[, i] <- factor(pbc[, i])
  }
}
```


### Analysis model
We are interested in the following model:
$$hepato \sim age + albumin + trig + bili + spiders$$


```{r}
fmla <- hepato ~ age + albumin + trig + bili + spiders
```

```{r, echo = F}
factors <- sapply(pbc[, all.vars(fmla)], is.factor)
factors["id"] <- NA
```
Where
``r names(factors[which(!factors)])[-sum(!factors, na.rm = T)]`` and 
``r names(factors[which(!factors)])[sum(!factors, na.rm = T)]``
are continuous, and
``r names(factors[which(factors)])[-sum(factors, na.rm = T)]``
and 
``r names(factors[which(factors)])[sum(factors, na.rm = T)]``
are categorical covariates.



The model specification using the **JointAI** package is very similar to the use of the
standard functions `lm()`, `glm()` or `lme()` (from the package **nlme**).
```{r, jm0, cache = T}
library(JointAI)
jm0 <- glm_imp(fixed = fmla, family = binomial(link = "logit"), data = pbc, n.iter = 500)
```

The (fixed effects) design matrix may also contain interaction terms, i.e.,
`age * albumin`, `age * albumin * trig` or `(age + albumin) * trig`, which may involve
incomplete covariates.

Non-linear associations between the covariates and the outcome 
are **only possible for complete covariates**, i.e., `log(age)`, `I(age^2)` or splines,
using the functions `ns()` or `bs()` from the package `splines`.


## Imputation models
**JointAI** will automatically check which variables in the design matrix are incomplete
and chose imputation models based on the type of the variable.
The default imputation model types are

* `norm`: linear regression for continuous variables,
* `logit`: logistic regression for factors with two categories,
* `multinomial`: multinomial logistic regression for unordered factors with > 2 categories, and
* `ordinal`: cumulative logistic regression for ordered factors with > 2 categories.

The columns of the design matrix will be ordered according to the number of missing values
in the covariates, starting with the ones with the least missing values.

The sequence and types of imputation models is specified in the `meth` argument.
If `meth = NULL`, the default imputation models and sequence are used. This can be changed
by supplying a named vector.

To use non-default choices, a convenient workflow is to do a initial call to `glm_imp()`
without doing the MCMC sampling (`n.adapt = 0` and `n.iter = 0`), extract the parameters
that need to be changed, and to call `glm_imp()` again with the changed parameters.

#### Example
It is important to make sure the imputation models fit the data well. A histogram of `trig`
reveals that (at least the marginal distribution of) `trig` is not symmetric. A log-normal
imputation model may fit the data better.
```{r, Histogramms of continuous incomplete variables, fig.width = 4, fig.height = 3}
par(mfrow = c(1,1), mar = c(3, 3, 2, 1), mgp = c(2, 0.6, 0))
hist(pbc$trig, nclass = 30, xlab = "value")
```


```{r, jm1, cache = T}
jm0 <- glm_imp(fmla, family = binomial(link = "logit"), data = pbc,
               n.adapt = 0, n.iter = 0)

# extract the vector of imputation methods
meth <- jm0$meth
meth

# change the imputation method for "trig"
meth["trig"] <- "lognorm"

# run the analysis and imputation with the changed setting
jm1 <- glm_imp(fmla, family = binomial(link = "logit"), data = pbc, meth = meth,
               n.iter = 500, overwrite = T)
```
We specifiy `overwrite = T` in order to allow **JointAI** to use the same file name
for the JAGS model as before (for more info see below).



## Posterior summary
The summary of this model can be displayed using the `summary` function
```{r}
summary(jm1)
```
In the top part of the summary, some characteristics of the sampling are given:

* the range of the iterations used for the summary (starting at 101, since the first 100
  iterations were used in the adaptive phase)
* the thinning interval
* the number of MCMC chains
* the number of iterations per chain

In the second part the posterior distribution of the parameters is given by

* the posterior mean
* the posterior standard deviation
* the 2.5% and 97.5% quantiles of the posterior sample

`summary()` also takes arguments `start`, `end` and `thin`, which allow to reduce the
sample used to calculate the posterior summary. Furthermore, a `subset` of variables 
can be selected. This can be done by specifying a vector of parameter names or the
column numbers in the `mcmc.list` object, e.g.,

```{r, eval = F}
summary(jm1, subset = c("age", "bili"))
summary(jm1, subset = c(2:4))
```
The default value `subset = "main"` selects the main parameters of the analysis model and
`subset = NULL` removes any selection.


## Plotting the MCMC sample
### Traceplots
The convergence of the MCMC chains can be checked using a traceplot:
```{r, fig.width = 7, fig.height = 5}
traceplot(jm1)
```
Each line represents the samples from one chain (3 chains are used by default) throughout
all iterations. If the sampler has converged, the lines should form a horizontal band with
no visual pattern. This is the case for all parameters.
(Formal criteria to evaluate convergence: see below)

### Density plots
The posterior density can be plotted using `densplot()`. 
The argument `vlines` can be used to add vertical reference lines, for instance to 
mark zero
```{r, fig.width = 7, fig.height = 5}
densplot(jm1, vlines = list(v = rep(0, 9)))
```

or to mark the posterior mean and 95% credible interval.
Together with the x-coordinates of the vertical lines (must be named "v"), graphical
parameters, that will be passed to `abline`, such as the line type `lwd`, color `col` 
or width `lwd`, can be supplied.
`
```{r, fig.width = 7, fig.height = 5}
densplot(jm1, vlines = list(list(v = rep(0, 9), col = grey(0.9)),
                            list(v = summary(jm1)$stats[, "Mean"], lty = 1, lwd = 2),
                            list(v = summary(jm1)$stats[, "2.5%"], lty = 2),
                            list(v = summary(jm1)$stats[, "97.5%"], lty = 2))
)
```


Analogue to `summary()`, the arguments `start`, `end`, `thin` and `subset` are available.



## Evaluation criteria
To evaluate the convergence and precision of the MCMC sample, two methods are available.

### Gelman-Rubin diagnostic
`gr_crit()` calls the function `gelman.diag()` from the package `coda` and allows for the
same options. Additionally, `subset`, `start`, `end` and `thin` can be specified.
```{r}
gr_crit(jm1)
```


### Monte-Carlo error
To assess the precision of the posterior estimate, the MC-error can be calculated using
the function `MC_error()` (which calles `mcse.mat()` from `mcmcse`) and then be compared 
to the parameter's posterior standard deviation.
A suggested rule of thumb is that the MC-error should not be more than 5% of the
parameter's posterior standard deviation.
```{r}
MCE <- MC_error(jm1)$scaled
MCE[, "se"] / summary(jm1)$stats[, "SD"] * 100
```
If the MC-error is too large, more MCMC samples may be necessary.

```{r, jm1a, cache = T}
jm1a <- glm_imp(fmla, family = binomial(link = "logit"), data = pbc, meth = meth,
               n.iter = 3000, overwrite = T)
MCEa <- MC_error(jm1a)$scaled
MCEa[, "se"] / summary(jm1a)$stats[, "SD"] * 100
```


The arguments `start`, `end`, `thin` and `subset` are available for the evaluation methods
as well.



## Reference categories for categorical covariates
By default, the first category of any factor (with two or more, ordered or unordered
categories) is chosen as reference.
When the reference category is a lot smaller than the other categories, this may result
in convergence problems. A better choice may then be to use the largest group as reference.

The reference category can be set using the argument `refcats`. Possible specifications
are:
```{r, eval = F}
refcats = "first" # (the default)
refcats = "largest" # largest category for all categorical variables
refcats = c(stage = 3) # 3rd category for stage and the default for all others
refcats = c(stage = "largest") # largest category for stage and the default for all others
refcats = c(stage = 3, spiders = "0") # 3rd category for stage and category "0" for spiders
```


#### Example
We will now include `stage` as covariate in the model.
```{r, jm2a, cache = T, message = F}
fmla2 <- update(fmla, .~. + stage)
table(pbc$stage, exclude = NULL)

jm2a <- glm_imp(fmla2, family = binomial(link = "logit"), data = pbc, n.iter = 500,
                overwrite = T)
jm2b <- glm_imp(fmla2, family = binomial(link = "logit"), data = pbc, n.iter = 500,
                refcats = "largest", overwrite = T)
```

```{r, fig.width = 7, fig.height = 5}
traceplot(jm2a)
```
The traceplot shows that the MCMC chains for the effect of `stage` have not converged.

Using the largest category (3) as reference solves this problem:
```{r, jm2b, cache = T, message = F}
jm2b <- glm_imp(fmla2, family = binomial(link = "logit"), data = pbc, n.iter = 500,
                refcats = "largest", overwrite = T)
```

```{r, fig.width = 7, fig.height = 5}
traceplot(jm2b)
```


## Auxiliary variables
Auxiliary variables are variables, that are not used in the analysis model of interest,
but provide information on missing covariates and should therefore be included as
predictors in the imputation models. It is possible to include such variables in 
**JointAI** via the `auxvars` argument.

```{r, jm3, cache = T}
jm3 <- glm_imp(fmla, family = binomial(link = "logit"), data = pbc, n.iter = 500,
               auxvars = c("trt", "sex", "platelet"), overwrite = T)
```

```{r}
summary(jm3, subset = NULL)
```




## Imputed datasets (and export to SPSS)
In order to extract a sample of the imputed values of the incomplete covariates, the MCMC
chains for those values need to be recorded. The argument `monitor_params` controls which
parameters are monitored. The default setting is to only follow the main parameters, that
is, the regression coefficients in the analysis model, the standard deviation of the 
residuals for continuous outcomes, and the random effects covariance matrix for repeated
outcomes. To get samples of the imputed values we need to add `imps = T` to the `monitor_params`
argument.
```{r, cache = T}
jm4 <- glm_imp(fmla, family = binomial(link = "logit"), data = pbc,
               meth = meth, n.iter = 500, 
               monitor_params = c(analysis_main = T, imps = T))
```

The summary and plotting methods will by default still only show the results for the main
parameters. The argument `subset` is used to control this. If it is set to `subset = NULL`
all parameters are shown. A specific subset can be chosen by either specifying the column
numbers of the columns in the MCMC output or the variable names. The default is `subset = "main"`.
```{r, fig.width = 7, fig.height = 6}
traceplot(jm4, subset = c("main", 21:30))
```


### Extracting multiple imputed datasets
A multiply imputed dataset can be extracted using the function `write_imp_spss`.
The argument `m` specifies the number of imputed datasets.
```{r, write_to_SPSS}
impDF <- write_imp_spss(jm4, m = 10, write_to_SPSS = F)

head(impDF)
```

Setting `write_to_SPSS = TRUE` (default) will write a .txt file containing the data and
a .sps file containing SPSS syntax to convert the imputed data into an SPSS dataset.
If no `filename` and `resdir` is specified, a default name will be generated and the
files written into the working directory.


### Analysis with multiply imputed data
Once multiple imputed datasets have been created, they can be analyzed analoguesly to 
imputed datasets that have been created with other packages. This can be done, for instance,
using the package **mitools**:
```{r, mitools}
library(mitools)

# make a list of data frames
splitDFs <- split(impDF, impDF$Imputation_)[-1]

# convert to imputationList object
miDFs <- imputationList(splitDFs)

# fit model on each imputed dataset
mods <- with(miDFs, glm(hepato ~ age + albumin + trig + bili + spiders,
                        family = binomial(link = "logit")))

pooled_results <- summary(MIcombine(MIextract(mods, fun = coef),
                                    MIextract(mods, fun = vcov)))

```


## Other elements of the `JointAI-object`
JAGS model file:
```{r}
jm1$mcmc_settings$modelfile
names(jm1$data_list)

jm1$data_list[-c(1:2)]
```

* `mu_reg_main` and `tau_reg_main` are the parameters of the priors for the regression coefficients in the analysis model
* `mu_reg_norm` and `tau_reg_norm` the parameters of the priors of the regression coefficients in the (log)normal imputation models
* `mu_reg_logit` and `tau_reg_logit` the parameters of the priors of the regression coefficients in the normal imputation model
* (`mu_reg_multinomial`, `tau_reg_logit`, `mu_reg_ordinal, `tau_reg_ordinal` analogue)