<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Theoretical Background • JointAI</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Theoretical Background">
<meta property="og:description" content="">
<meta property="og:image" content="https://nerler.github.io/JointAI/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-127879026-4"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127879026-4');
</script>
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">JointAI</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.6.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/AfterFitting.html">After Fitting</a>
    </li>
    <li>
      <a href="../articles/MCMCsettings.html">MCMC Settings</a>
    </li>
    <li>
      <a href="../articles/MinimalExample.html">Minimal Example</a>
    </li>
    <li>
      <a href="../articles/ModelSpecification.html">Model Specification</a>
    </li>
    <li>
      <a href="../articles/SelectingParameters.html">Parameter Selection</a>
    </li>
    <li>
      <a href="../articles/TheoreticalBackground.html">Theoretical Background</a>
    </li>
    <li>
      <a href="../articles/VisualizingIncompleteData.html">Visualizing Incomplete Data</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/nerler/JointAI">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/N_Erler">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Theoretical Background</h1>
                        <h4 class="author">Nicole Erler</h4>
            
            <h4 class="date">2019-08-28</h4>
      
      
      <div class="hidden name"><code>TheoreticalBackground.Rmd</code></div>

    </div>

    
    
<p>Consider the general setting of a regression model where interest lies in a set
of parameters <span class="math inline">\(\boldsymbol\theta\)</span> that describe the association between a univariate outcome
<span class="math inline">\(\mathbf y\)</span> and a set of covariates <span class="math inline">\(\mathbf X = (\mathbf x_1, \ldots, \mathbf x_p)\)</span>.
In the Bayesian framework, inference over <span class="math inline">\(\boldsymbol\theta\)</span> is obtained
by estimation of the posterior distribution of <span class="math inline">\(\boldsymbol\theta\)</span>, which is proportional
to the product of the likelihood of the data <span class="math inline">\((\mathbf y, \mathbf X)\)</span>
and the prior distribution of <span class="math inline">\(\boldsymbol\theta\)</span>,
<span class="math display">\[ p(\boldsymbol\theta\mid \mathbf y, \mathbf X) \propto
p(\mathbf y, \mathbf X \mid \boldsymbol\theta)\,p(\boldsymbol\theta).\]</span></p>
<p>When some of the covariates are incomplete, <span class="math inline">\(\mathbf X\)</span> consists of two parts,
the completely observed variables <span class="math inline">\(\mathbf X_{obs}\)</span> and those variables
that are incomplete, <span class="math inline">\(\mathbf X_{mis}\)</span>.
If <span class="math inline">\(\mathbf y\)</span> had missing values (and this missingness was ignorable),
the only necessary change in the formulas below
would be to replace <span class="math inline">\(\mathbf y\)</span> by <span class="math inline">\(\mathbf y_{mis}\)</span>.
Here, we will, therefore, consider <span class="math inline">\(\mathbf y\)</span> to be completely observed.
In the implementation in the R package <strong>JointAI</strong>, however,
missing values in the outcome are allowed and are imputed automatically.</p>
<p>The likelihood of the complete data, i.e., observed and unobserved data,
can be factorized in the following convenient way:
<span class="math display">\[p(\mathbf y, \mathbf X_{obs}, \mathbf X_{mis} \mid \boldsymbol\theta) =
p(\mathbf y \mid \mathbf X_{obs}, \mathbf X_{mis}, \boldsymbol\theta_{y\mid x})\,
p(\mathbf X_{mis} \mid \mathbf X_{obs}, \boldsymbol\theta_x),
\]</span>
where the first factor constitutes the analysis model of interest,
described by a vector of parameters <span class="math inline">\(\boldsymbol\theta_{y\mid x}\)</span>, and the second
factor is the joint distribution of the incomplete variables,
i.e., the imputation part of the model,
described by parameters <span class="math inline">\(\boldsymbol\theta_x\)</span>, and
<span class="math inline">\(\boldsymbol\theta = (\boldsymbol\theta_{y\mid x}^\top, \boldsymbol\theta_x^\top)^\top\)</span>.</p>
<p>Explicitly specifying the joint distribution of all
data is one of the major advantages of the Bayesian approach,
since this facilitates the use of all available information
of the outcome in the imputation of the incomplete covariates <span class="citation">(Erler et al. 2016)</span>,
which becomes especially relevant for more complex outcomes like repeatedly
measured variables (see section on <a href="#sec:impLong">imputation with longitudinal outcomes</a>).</p>
<p>In complex models the posterior distribution can usually not be derived
analytically but MCMC methods are used to obtain samples
from the posterior distribution.
The MCMC sampling in <strong>JointAI</strong> is done using Gibbs sampling,
which iteratively samples from the full conditional distributions of the unknown
parameters and missing values.</p>
<p>In the following sections we describe each of the three parts of the model,
the analysis model, the imputation part and the prior distributions, in detail.</p>
<div id="sec:AnalysisModel" class="section level2">
<h2 class="hasAnchor">
<a href="#sec:AnalysisModel" class="anchor"></a>Analysis model</h2>
<p>The analysis model of interest is described by the probability density function
<span class="math inline">\(p(\mathbf y \mid \mathbf X, \boldsymbol\theta_{y\mid x})\)</span>.
The R package <strong>JointAI</strong> can currently handle analysis models that are
either generalized linear regression models (GLM),
generalized linear mixed models (GLMM),
cumulative logit (mixed) models, parametric (Weibull) survival models or Cox proportional hazards models.</p>
<div id="generalized-linear-mixed-models" class="section level3">
<h3 class="hasAnchor">
<a href="#generalized-linear-mixed-models" class="anchor"></a>Generalized linear (mixed) models</h3>
<p>For a GLM the probability density function is chosen from the exponential family
and has the linear predictor
<span class="math display">\[g\{E(y_i\mid \mathbf X, \boldsymbol\theta_{y\mid x})\} = \mathbf x_i^\top\boldsymbol\beta,\]</span>
where <span class="math inline">\(g(\cdot)\)</span> is a link function, <span class="math inline">\(y_i\)</span> the value of the outcome variable
for subject <span class="math inline">\(i\)</span>, and <span class="math inline">\(\mathbf x_i\)</span> is a column vector containing the row of
<span class="math inline">\(\mathbf X\)</span> that contains the covariate information for <span class="math inline">\(i\)</span>.</p>
<p>For a GLMM the linear predictor is of the form
<span class="math display">\[g\{E(y_{ij}\mid \mathbf X, \mathbf b_i, \boldsymbol\theta_{y\mid x})\} = \mathbf x_{ij}^\top\boldsymbol\beta + \mathbf z_{ij}^\top\mathbf b_i,\]</span>
where <span class="math inline">\(y_{ij}\)</span> is the <span class="math inline">\(j\)</span>-th outcome of subject <span class="math inline">\(i\)</span>, <span class="math inline">\(\mathbf x_{ij}\)</span> is the
corresponding vector of covariate values, <span class="math inline">\(\mathbf b_i\)</span> a vector of random effects
pertaining to subject <span class="math inline">\(i\)</span>,
and <span class="math inline">\(\mathbf z_{ij}\)</span> a column vector containing the row of the design matrix of the random effects, <span class="math inline">\(\mathbf Z\)</span>,
that corresponds to the <span class="math inline">\(j\)</span>-th measurement of subject <span class="math inline">\(i\)</span>.
<span class="math inline">\(\mathbf Z\)</span> typically contains a subset of the variables in <span class="math inline">\(\mathbf X\)</span>, and
<span class="math inline">\(\mathbf b_i\)</span> follows a normal distribution with mean zero and covariance matrix
<span class="math inline">\(\mathbf D\)</span>.</p>
<p>In both cases the parameter vector <span class="math inline">\(\boldsymbol\theta_{y\mid x}\)</span> contains the
regression coefficients <span class="math inline">\(\boldsymbol\beta\)</span>, and potentially additional variance
parameters (e.g., for linear (mixed) models), for which prior distributions
will be specified in the section on <a href="#sec:priors">prior distributions</a>.</p>
</div>
<div id="cumulative-logit-mixed-models" class="section level3">
<h3 class="hasAnchor">
<a href="#cumulative-logit-mixed-models" class="anchor"></a>Cumulative logit (mixed) models</h3>
<p>Cumulative logit mixed models are of the form
<span class="math display">\[\begin{eqnarray*}
y_{ij} &amp;\sim&amp; \text{Mult}(\pi_{ij,1}, \ldots, \pi_{ij,K}),\\[2ex]
\pi_{ij,1} &amp;=&amp; P(y_{ij} \leq 1),\\
\pi_{ij,k} &amp;=&amp; P(y_{ij} \leq k) - P(y_{ij} \leq k-1), \quad k \in 2, \ldots, K-1,\\
\pi_{ij,K} &amp;=&amp; 1 - \sum_{k = 1}^{K-1}\pi_{ij,k},\\[2ex]
\text{logit}(P(y_{ij} \leq k)) &amp;=&amp; \gamma_k + \eta_{ij}, \quad k \in 1,\ldots,K,\\
\eta_{ij} &amp;=&amp; \mathbf x_{ij}^\top\boldsymbol\beta + \mathbf z_{ij}^\top\mathbf b_i,\\[2ex]
\gamma_1,\delta_1,\ldots,\delta_{K-1} &amp;\overset{iid}{\sim}&amp; N(\mu_\gamma, \sigma_\gamma^2),\\
\gamma_k &amp;\sim&amp; \gamma_{k-1} + \exp(\delta_{k-1}),\quad k = 2,\ldots,K,
\end{eqnarray*}\]</span>
where <span class="math inline">\(\pi_{ij,k} = P(y_{ij} = k)\)</span> and <span class="math inline">\(\text{logit}(x) = \log\left(\frac{x}{1-x}\right)\)</span>.
A cumulative logit regression model for a univariate outcome <span class="math inline">\(y_i\)</span> can be
obtained by dropping the index <span class="math inline">\(j\)</span> and omitting <span class="math inline">\(\mathbf z_{ij}^\top\mathbf b_i\)</span>.
In cumulative logit (mixed) models, the design matrix <span class="math inline">\(\mathbf X\)</span> does not contain
an intercept, since outcome category specific intercepts <span class="math inline">\(\gamma_1,\ldots, \gamma_K\)</span>
are specified. Here, the parameter vector <span class="math inline">\(\boldsymbol \theta_{y\mid x}\)</span> includes
the regression coefficients <span class="math inline">\(\boldsymbol\beta\)</span>, the first intercept <span class="math inline">\(\gamma_1\)</span>
and increments <span class="math inline">\(\delta_1, \ldots, \delta_{K-1}\)</span>.</p>
</div>
<div id="survival-models" class="section level3">
<h3 class="hasAnchor">
<a href="#survival-models" class="anchor"></a>Survival models</h3>
<p>Survival data are typically characterized by the observed event or censoring times,
<span class="math inline">\(T_i\)</span>, and the event indicator, <span class="math inline">\(D_i\)</span>, which is one if the event was observed
and zero otherwise.
<strong>JointAI</strong> provides two types of models to analyse right censored survival data,
a parametric model which assumes a Weibull distribution for the true
(but partially unobserved) survival times <span class="math inline">\(T^*\)</span>, and a semi-parametric
Cox proportional hazards model.</p>
<p>The parametric survival model is implemented as
<span class="math display">\[\begin{eqnarray*}
T_i^* &amp;\sim&amp; \text{Weibull}(1, r_i, s),\\
D_i &amp;\sim&amp; \unicode{x1D7D9}(T_i^* \geq C_i),\\
\log(r_j) &amp;=&amp; - \mathbf x_i^\top\boldsymbol\beta,\\
s &amp;\sim&amp; \text{Exp}(0.01),
\end{eqnarray*}\]</span>
where <span class="math inline">\(\unicode{x1D7D9}\)</span> is the indicator function which is one if <span class="math inline">\(T_i^*\geq C_i\)</span>, and zero otherwise.</p>
<p>The Cox proportional hazards model can be written as
<span class="math display">\[h_i(t) = h_0(t)\exp(\mathbf X_i \boldsymbol\beta),\]</span>
where <span class="math inline">\(h_0(t)\)</span> is the baseline hazard function, which, in <strong>JointAI</strong>,
we model using a B-spline approach with six degrees of freedom, i.e.,
<span class="math inline">\(h_0(t) = \sum_{q = 1}^6 \gamma_{Bq} B_q(t),\)</span> where <span class="math inline">\(B_q\)</span> denotes the <span class="math inline">\(q\)</span>-th basis
function.</p>
<p>The survival function of the Cox model is
<span class="math display">\[S(t\mid \boldsymbol\theta) = \exp\left\{-\int_0^th_0(s)\exp\left(\mathbf X_i\boldsymbol\beta\right)ds\right\} = \exp\left\{-\exp\left(\mathbf X_i\boldsymbol\beta\right)\int_0^th_0(s)ds\right\},\]</span>
where <span class="math inline">\(\boldsymbol\theta\)</span> includes the regression coefficients <span class="math inline">\(\boldsymbol\beta\)</span>
(which do not contain an intercept) and the coefficients
<span class="math inline">\(\boldsymbol \gamma_{B}\)</span> used in the specification of the baseline hazard.
Since the integral over the baseline hazard does not have a closed-form solution,
in <strong>JointAI</strong> it is approximated using Gauss-Kronrod quadrature with 15
evaluation points.</p>
</div>
</div>
<div id="imputation-part" class="section level2">
<h2 class="hasAnchor">
<a href="#imputation-part" class="anchor"></a>Imputation part</h2>
<p>A convenient way to specify the joint distribution of the incomplete covariates
<span class="math inline">\(\mathbf X_{mis} = (\mathbf x_{mis_1}, \ldots, \mathbf x_{mis_q})\)</span> is to use
a sequence of conditional univariate distributions <span class="citation">(Ibrahim, Chen, and Lipsitz 2002; Erler et al. 2016)</span>
<!--  -->
<span class="math display" id="eq:factorization">\[\begin{eqnarray}
p(\mathbf x_{mis_1}, \ldots, \mathbf x_{mis_q} \mid \mathbf X_{obs}, \boldsymbol\theta_{x})
&amp; = &amp; p(\mathbf x_{mis_1} \mid \mathbf X_{obs}, \boldsymbol\theta_{x_1})\\
&amp;   &amp; \prod_{\ell=2}^q p(\mathbf x_{mis_{\ell}} \mid \mathbf X_{obs}, \mathbf x_{mis_1},
\ldots, \mathbf x_{mis_{\ell-1}}, \boldsymbol\theta_{x_\ell}),\tag{1}
\end{eqnarray}\]</span>
with <span class="math inline">\(\boldsymbol\theta_{x} = (\boldsymbol\theta_{x_1}^\top, \ldots, \boldsymbol\theta_{x_q}^\top)^\top\)</span>.</p>
<p>Each of the conditional distributions is a member of the exponential family,
extended with distributions for ordinal categorical variables,
and chosen according to the type of the respective variable.
Its linear predictor is
<span class="math display">\[
g_\ell\left\{E\left(x_{i,mis_\ell} \mid \mathbf x_{i,obs},
\mathbf x_{i, mis_{&lt;\ell}},
\boldsymbol\theta_{x_\ell}\right)
\right\} = (\mathbf x_{i, obs}^\top, x_{i, mis_1},
\ldots, x_{i, mis_{\ell-1}}) \boldsymbol\alpha_{\ell},
\quad \ell=1,\ldots,q,
\]</span>
where <span class="math inline">\(\mathbf x_{i,mis_{&lt;\ell}} = (x_{i,mis_1}, \ldots, x_{i,mis_{\ell-1}})^\top\)</span>
and <span class="math inline">\(\mathbf x_{i,obs}\)</span> is the vector of values for subject <span class="math inline">\(i\)</span> of those covariates
that are observed for all subjects.</p>
<p>Factorization of the joint distribution of the covariates in such a sequence
yields a straightforward specification of the joint distribution, even when the
covariates are of mixed type.</p>
<p>Missing values in the covariates are sampled from their full-conditional
distribution that can be derived from the full joint distribution of outcome
and covariates.</p>
<p>When, for instance, the analysis model is a GLM, the full conditional
distribution of an incomplete covariate <span class="math inline">\(x_{i, mis_{\ell}}\)</span> can be written as
<span class="math display" id="eq:fullcond">\[\begin{eqnarray} \nonumber
p(x_{i, mis_{\ell}} \mid \mathbf y_i, \mathbf x_{i,obs},
\mathbf x_{i,mis_{-\ell}}, \boldsymbol\theta)
&amp;\propto&amp; p \left(y_i \mid \mathbf x_{i, obs}, \mathbf x_{i, mis},
\boldsymbol\theta_{y\mid x}
\right)
p(\mathbf x_{i, mis}\mid \mathbf x_{i, obs}, \boldsymbol\theta_{x})\,
p(\boldsymbol\theta_{y\mid x})\, p(\boldsymbol\theta_{x})\\\nonumber
&amp;\propto&amp; p \left(y_i \mid \mathbf x_{i, obs}, \mathbf x_{i, mis},
\boldsymbol\theta_{y\mid x}
\right)\\\nonumber
&amp;        &amp; p(x_{i, mis_\ell} \mid \mathbf x_{i, obs}, \mathbf x_{i, mis_{&lt;\ell}}, \boldsymbol\theta_{x_\ell})\\\nonumber
&amp;        &amp; \left\{
\prod_{k=\ell+1}^q p(x_{i,mis_k}\mid \mathbf x_{i, obs},
\mathbf x_{i, mis_{&lt;k}},
\boldsymbol\theta_{x_k})
\right\}\\
&amp;        &amp; p(\boldsymbol\theta_{y\mid x}) p(\boldsymbol\theta_{x_\ell})
\prod_{k=\ell+1}^p p(\boldsymbol\theta_{x_k}), \tag{2}
\end{eqnarray}\]</span>
where <span class="math inline">\(\boldsymbol\theta_{x_{\ell}}\)</span> is the vector of parameters describing the model
for the <span class="math inline">\(\ell\)</span>-th covariate, and contains the vector of regression coefficients
<span class="math inline">\(\boldsymbol\alpha_\ell\)</span> and potentially additional (variance) parameters.
The product of distributions enclosed by curly brackets represents the
distributions of those covariates that have <span class="math inline">\(x_{mis_\ell}\)</span> as a predictive
variable in the specification of the sequence in <a href="#eq:factorization">(1)</a>.</p>
<p>Even though <a href="#eq:fullcond">(2)</a> describes the actual imputation model,
i.e., the distribution the imputed values for <span class="math inline">\(x_{i, mis_{\ell}}\)</span> are sampled from,
we will use the term ``imputation model’’ for the conditional distribution
of <span class="math inline">\(x_{i, mis_{\ell}}\)</span> from <a href="#eq:factorization">(1)</a>, since the latter is
the distribution that is explicitly specified by the user and, hence, of more
relevance when using <strong>JointAI</strong>.</p>
<div id="sec:impLong" class="section level3">
<h3 class="hasAnchor">
<a href="#sec:impLong" class="anchor"></a>Imputation with longitudinal outcomes</h3>
<p>Factorizing the joint distribution into analysis model and imputation part
also facilitates extensions to settings with more complex outcomes,
such as repeatedly measured outcomes.
In the case where the analysis model is a GLMM or ordinal mixed model,
the conditional distribution of the outcome in <a href="#eq:fullcond">(2)</a>,
<span class="math inline">\(p\left(y_i \mid \mathbf x_{i, obs}, \mathbf x_{i, mis}, \boldsymbol\theta_{y\mid x} \right),\)</span>
has to be replaced by
<span class="math display" id="eq:lmmpartfullcond">\[\begin{eqnarray}
\left\{\prod_{j=1}^{n_i} p \left(y_{ij} \mid \mathbf x_{i, obs},
\mathbf x_{i, mis}, \mathbf b_i,
\boldsymbol\theta_{y\mid x}\right)
\right\}. \tag{3}
\end{eqnarray}\]</span>
Since <span class="math inline">\(\mathbf y\)</span> does not appear in any of the other terms in <a href="#eq:fullcond">(2)</a>,
and <a href="#eq:lmmpartfullcond">(3)</a> can be chosen to be a model that is appropriate
for the outcome at hand, the thereby specified full conditional distribution
of <span class="math inline">\(x_{i, mis_\ell}\)</span> allows us to draw valid imputations that use all available
information on the outcome.</p>
<p>This is an important difference to standard FCS, where the full conditional
distributions used to impute missing values are specified directly, usually
as regression models, and require the outcome to be explicitly included into
the linear predictor of the imputation model. In settings with complex outcomes
it is not clear how this should be done and simplifications may lead to biased
results <span class="citation">(Erler et al. 2016)</span>.
The joint model specification utilized in <strong>JointAI</strong> overcomes this difficulty.</p>
<p>When some of the covariates are time-varying, it is convenient to specify models
for these variables in the beginning of the sequence of covariate models, so
that models for longitudinal variables have other longitudinal and baseline
covariates in their linear predictor, but longitudinal covariates do not
enter the predictors of baseline covariates.</p>
<p>Note that, whenever there are incomplete baseline covariates it is necessary
to specify models for all longitudinal variables, even completely observed ones,
while models for completely observed baseline covariates can be omitted.
This becomes clear when we extend the factorized joint distribution from above
with completely and incompletely observed longitudinal (level-1)
covariates <span class="math inline">\(\mathbf s_{obs}\)</span> and <span class="math inline">\(\mathbf s_{mis}\)</span>:
<span class="math display">\[\begin{multline*}
p \left(y_{ij} \mid \mathbf s_{ij, obs}, \mathbf s_{ij, mis},
\mathbf x_{i, obs}, \mathbf x_{i, mis}, \boldsymbol\theta_{y\mid x} \right)\\
p(\mathbf s_{ij, mis}\mid \mathbf s_{ij, obs}, \mathbf x_{i, obs},
\mathbf x_{i, mis}, \boldsymbol\theta_{s_{mis}})\,
p(\mathbf s_{ij, obs}\mid \mathbf x_{i, obs}, \mathbf x_{i, mis},
\boldsymbol\theta_{s_{obs}})\\
p(\mathbf x_{i, mis}\mid \mathbf x_{i, obs}, \boldsymbol\theta_{x_{mis}})\,
p(\mathbf x_{i, obs} \mid \boldsymbol\theta_{x_{obs}})\,
p(\boldsymbol\theta_{y\mid x})\, p(\boldsymbol\theta_{s_{mis}}) \,
p(\boldsymbol\theta_{s_{obs}})\, p(\boldsymbol\theta_{x_{mis}}) \,
p(\boldsymbol\theta_{x_{obs}})
\end{multline*}\]</span>
Given that the parameter vectors <span class="math inline">\(\theta_{x_{obs}}\)</span>, <span class="math inline">\(\theta_{x_{mis}}\)</span>, <span class="math inline">\(\theta_{s_{obs}}\)</span>
and <span class="math inline">\(\theta_{s_{mis}}\)</span> are a priori independent, and
<span class="math inline">\(p(\mathbf x_{i, obs} \mid \boldsymbol\theta_{x_{obs}})\)</span> is independent of
both <span class="math inline">\(x_{mis}\)</span> and <span class="math inline">\(s_{mis}\)</span>, it can be omitted.</p>
<p>Since <span class="math inline">\(p(\mathbf s_{ij, obs}\mid \mathbf x_{i, obs}, \mathbf x_{i, mis}, \boldsymbol\theta_{s_{obs}})\)</span>,
however, has <span class="math inline">\(\mathbf x_{i, mis}\)</span> in its linear predictor and will, hence, be
part of the full conditional distribution of <span class="math inline">\(\mathbf x_{i, mis}\)</span>, it cannot
be omitted from the model.</p>

</div>
<div id="non-linear-associations-and-interactions" class="section level3">
<h3 class="hasAnchor">
<a href="#non-linear-associations-and-interactions" class="anchor"></a>Non-linear associations and interactions</h3>
<p>Other settings in which the fully Bayesian approach employed in <strong>JointAI</strong>
has an advantage over standard FCS are settings with interaction terms that
involve incomplete covariates or when the association of the outcome with an
incomplete covariate is non-linear.
In standard FCS such settings lead to incompatible imputation models
<span class="citation">(White, Royston, and Wood 2011; Bartlett et al. 2015)</span>.
This becomes clear when considering the following simple example
where the analysis model of interest is the linear regression
<span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i\)</span>
and <span class="math inline">\(x_i\)</span> is imputed using
<span class="math inline">\(x_i = \alpha_0 + \alpha_1 y_i + \tilde\varepsilon_i\)</span>.
While the analysis model assumes a quadratic relationship, the imputation model
assumes a linear association between <span class="math inline">\(\mathbf x\)</span> and <span class="math inline">\(\mathbf y\)</span> and there cannot
be a joint distribution that
has the imputation and analysis model as its full conditional distributions.</p>
<p>Because, in <strong>JointAI</strong>, the analysis model is a factor in the full conditional distribution
that is used to impute <span class="math inline">\(x_i\)</span>, the non-linear association is
taken into account. Furthermore, since it is the joint distribution that is
specified, and the full conditional then derived from it, the joint distribution
is ensured to exist.</p>
</div>
</div>
<div id="sec:priors" class="section level2">
<h2 class="hasAnchor">
<a href="#sec:priors" class="anchor"></a>Prior distributions</h2>
<p>Prior distributions have to be specified for all (hyper)parameters.
A common prior choice for the regression coefficients is the normal distribution
with mean zero and large variance.
In <strong>JointAI</strong> variance parameters in models for normally distributed variables are
specified as, by default vague, inverse-gamma distributions.</p>
<p>The covariance matrix of the random effects in a mixed model, <span class="math inline">\(\mathbf D\)</span>,
is assumed to follow an inverse Wishart distribution where the degrees of freedom
are usually chosen to be equal to the dimension of the random effects, and the
scale matrix is diagonal. Since the magnitude of the diagonal elements relates
to the variance of the random effects, the choice of suitable values depends on the
scale of the variable the random effect is associated with. Therefore, <strong>JointAI</strong>
uses independent gamma hyperpriors for each of the diagonal elements.
More details about the default hyperparameters and how to change them are given
in the section on <a href="https://nerler.github.io/JointAI/articles/ModelSpecification.html#hyperparameters">hyperparameters in the vignette about Model Specification</a>.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-Bartlett2015">
<p>Bartlett, JW, SR Seaman, IR White, and JR Carpenter. 2015. “Multiple Imputation of Covariates by Fully Conditional Specification: Accommodating the Substantive Model.” <em>Statistical Methods in Medical Research</em>. <a href="https://doi.org/10.1177/0962280214521348">https://doi.org/10.1177/0962280214521348</a>.</p>
</div>
<div id="ref-Erler2016">
<p>Erler, NS, D Rizopoulos, J van Rosmalen, VWV Jaddoe, OH Franco, and EMEH Lesaffre. 2016. “Dealing with Missing Covariates in Epidemiologic Studies: A Comparison Between Multiple Imputation and a Full Bayesian Approach.” <em>Statistics in Medicine</em> 35 (17): 2955–74. <a href="https://doi.org/10.1002/sim.6944">https://doi.org/10.1002/sim.6944</a>.</p>
</div>
<div id="ref-Ibrahim2002">
<p>Ibrahim, JG, MH, Chen, and SR Lipsitz. 2002. “Bayesian Methods for Generalized Linear Models with Covariates Missing at Random.” <em>Canadian Journal of Statistics</em>. <a href="https://doi.org/10.2307/3315865">https://doi.org/10.2307/3315865</a>.</p>
</div>
<div id="ref-White2011">
<p>White, IR, P Royston, and AM Wood. 2011. “Multiple Imputation Using Chained Equations: Issues and Guidance for Practice.” <em>Statistics in Medicine</em>. <a href="https://doi.org/10.1002/sim.4067">https://doi.org/10.1002/sim.4067</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#sec:AnalysisModel">Analysis model</a><ul class="nav nav-pills nav-stacked">
<li><a href="#generalized-linear-mixed-models">Generalized linear (mixed) models</a></li>
      <li><a href="#cumulative-logit-mixed-models">Cumulative logit (mixed) models</a></li>
      <li><a href="#survival-models">Survival models</a></li>
      </ul>
</li>
      <li>
<a href="#imputation-part">Imputation part</a><ul class="nav nav-pills nav-stacked">
<li><a href="#sec:impLong">Imputation with longitudinal outcomes</a></li>
      <li><a href="#non-linear-associations-and-interactions">Non-linear associations and interactions</a></li>
      </ul>
</li>
      <li><a href="#sec:priors">Prior distributions</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Nicole S. Erler.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script>
  docsearch({
    
    
    apiKey: '0d21d69e7c3eb00e029f5b8d9424cd56',
    indexName: 'jointal',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
