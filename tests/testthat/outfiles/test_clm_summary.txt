[[1]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ 1, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
     Mean SD 2.5% 97.5% tail-prob. GR-crit MCE/SD

Posterior summary of the intercepts:
           Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  1.12038 0.187  0.833  1.484      0.000   1.516 0.2027
O1 > 2 -0.00108 0.156 -0.237  0.240      0.933   0.981 0.1826
O1 > 3 -1.29248 0.235 -1.622 -0.895      0.000   1.009 0.0786


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[2]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O2 ~ 1, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
     Mean SD 2.5% 97.5% tail-prob. GR-crit MCE/SD

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O2 > 1  1.209 0.210  0.742  1.559      0.000   1.136  0.183
O2 > 2  0.175 0.214 -0.207  0.497      0.467   1.345  0.183
O2 > 3 -1.012 0.222 -1.396 -0.611      0.000   0.999  0.125


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[3]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C1, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
    Mean   SD  2.5% 97.5% tail-prob. GR-crit MCE/SD
C1 -2.43 12.9 -31.8  16.1      0.867    1.17  0.183

Posterior summary of the intercepts:
          Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.9572 0.191  0.663  1.311        0.0    2.15  0.308
O1 > 2 -0.0435 0.156 -0.357  0.230        0.6    1.02  0.183
O1 > 3 -1.3243 0.216 -1.669 -0.964        0.0    1.09  0.183


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[4]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O2 ~ C1, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
   Mean   SD  2.5% 97.5% tail-prob. GR-crit MCE/SD
C1 10.1 17.1 -24.2  36.8      0.467    1.15  0.183

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O2 > 1  1.357 0.211  0.927  1.643      0.000    1.67 0.2223
O2 > 2  0.217 0.234 -0.146  0.620      0.333    1.21 0.1826
O2 > 3 -0.966 0.279 -1.392 -0.522      0.000    1.24 0.0744


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[5]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C2, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
    Mean    SD  2.5% 97.5% tail-prob. GR-crit MCE/SD
C2 -0.18 0.627 -1.43 0.804      0.867    1.23  0.183

Posterior summary of the intercepts:
          Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  1.0353 0.275  0.610  1.631      0.000    1.39  0.183
O1 > 2  0.0112 0.244 -0.456  0.522      0.867    1.31  0.108
O1 > 3 -1.2521 0.260 -1.687 -0.805      0.000    1.03  0.100


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[6]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O2 ~ C2, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
     Mean    SD  2.5%  97.5% tail-prob. GR-crit MCE/SD
C2 -0.915 0.564 -1.88 0.0835     0.0667    2.65  0.339

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O2 > 1  1.250 0.240  0.940  1.753      0.000    1.25  0.263
O2 > 2  0.155 0.184 -0.118  0.471      0.467    1.06  0.183
O2 > 3 -1.090 0.208 -1.546 -0.752      0.000    1.31  0.183


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

$cov1

Bayesian linear model fitted with JointAI

Call:
lm_imp(formula = C1 ~ O1, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
               Mean     SD     2.5%  97.5% tail-prob. GR-crit MCE/SD
(Intercept) 1.43646 0.0119  1.42706 1.4766      0.000    1.09  0.183
O1.L        0.00639 0.0273 -0.01407 0.0973      0.867    1.21  0.183
O1.Q        0.01235 0.0609 -0.02632 0.1601      1.000    1.97  0.183
O1.C        0.00936 0.0253 -0.00382 0.0947      0.667    1.20  0.183

Posterior summary of residual std. deviation:
           Mean     SD   2.5% 97.5% GR-crit MCE/SD
sigma_C1 0.0288 0.0303 0.0165 0.113    1.42  0.183


MCMC settings:
Iterations = 1:10
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

$cov2

Bayesian linear model fitted with JointAI

Call:
lm_imp(formula = C1 ~ O2, data = wideDF, n.adapt = 5, n.iter = 10, 
    seed = 2020)


Posterior summary:
                Mean      SD     2.5%   97.5% tail-prob. GR-crit MCE/SD
(Intercept) 1.432507 0.00343  1.42709 1.43886      0.000    1.24  0.183
O22         0.002802 0.00493 -0.00800 0.00956      0.533    1.17  0.183
O23         0.003139 0.00486 -0.00781 0.01135      0.467    1.42  0.183
O24         0.000306 0.00445 -0.00853 0.00587      0.867    1.20  0.183

Posterior summary of residual std. deviation:
           Mean      SD   2.5%  97.5% GR-crit MCE/SD
sigma_C1 0.0193 0.00138 0.0173 0.0223     1.8  0.183


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[9]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ M2 + O2 * abs(C1 - C2) + log(C1), data = wideDF, 
    n.adapt = 5, n.iter = 10, seed = 2020)


Posterior summary:
                    Mean     SD    2.5%  97.5% tail-prob. GR-crit MCE/SD
M22              -0.4105  0.369  -1.016  0.335      0.267    1.18  0.183
M23              -0.4481  0.472  -1.150  0.251      0.467    1.66  0.330
M24              -0.5045  0.392  -1.266  0.193      0.200    1.40  0.278
O22               1.4913  0.664   0.473  2.572      0.000    2.32  0.333
O23               2.6302  1.170   1.369  5.263      0.000    5.30  0.587
O24               0.2531  0.909  -0.675  2.193      0.800    5.59  0.389
abs(C1 - C2)     -0.0025  0.668  -1.117  1.251      1.000    2.27  0.183
log(C1)          -1.3370 19.798 -41.099 32.590      0.800    1.16  0.183
O22:abs(C1 - C2) -0.4854  0.501  -1.155  0.557      0.400    2.10  0.445
O23:abs(C1 - C2) -0.8662  0.739  -2.472  0.118      0.200    3.77  0.539
O24:abs(C1 - C2)  0.1557  0.668  -1.392  0.775      0.533    9.69  0.571

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.242 0.477 -0.698  0.843      0.467    9.87  0.622
O1 > 2 -0.821 0.529 -1.910 -0.298      0.000    7.74  1.073
O1 > 3 -2.118 0.513 -3.140 -1.459      0.000    5.16  1.036


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[10]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ ifelse(as.numeric(O2) > as.numeric(M1), 
    1, 0) * abs(C1 - C2) + log(C1), data = wideDF, n.adapt = 5, 
    n.iter = 10, seed = 2020, warn = FALSE)


Posterior summary:
                                                             Mean     SD
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0)               1.696  1.131
abs(C1 - C2)                                                0.384  0.708
log(C1)                                                    -8.016 18.092
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0):abs(C1 - C2) -0.551  0.824
                                                              2.5% 97.5%
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0)                0.251  3.54
abs(C1 - C2)                                                -0.896  1.64
log(C1)                                                    -42.843 22.21
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0):abs(C1 - C2)  -1.785  0.54
                                                           tail-prob. GR-crit
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0)                   0.000   10.19
abs(C1 - C2)                                                    0.533    1.72
log(C1)                                                         0.667    1.27
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0):abs(C1 - C2)      0.800    8.80
                                                           MCE/SD
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0)               0.389
abs(C1 - C2)                                                0.183
log(C1)                                                     0.183
ifelse(as.numeric(O2) > as.numeric(M1), 1, 0):abs(C1 - C2)  0.865

Posterior summary of the intercepts:
          Mean    SD   2.5% 97.5% tail-prob. GR-crit MCE/SD
O1 > 1  1.0654 0.180  0.704  1.40      0.000    2.08  0.188
O1 > 2 -0.0107 0.192 -0.307  0.34      0.933    1.61  0.183
O1 > 3 -1.3736 0.224 -1.759 -1.00      0.000    1.12  0.183


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[11]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C1 + C2 + M2 + O2, data = wideDF, n.adapt = 5, 
    n.iter = 10, nonprop = list(O1 = ~C1 + C2), seed = 2020)


Posterior summary:
           Mean     SD    2.5%  97.5% tail-prob. GR-crit MCE/SD
M22      0.2722  0.386  -0.393  0.867     0.6667    1.61  0.183
M23      0.4187  0.346  -0.204  1.006     0.2667    1.91  0.221
M24      0.0613  0.458  -0.771  0.751     0.9333    1.94  0.183
O22      0.4512  0.660  -0.524  1.655     0.6000    1.58  0.460
O23      1.1165  0.532   0.161  1.905     0.0667    1.89  0.305
O24      0.3852  0.533  -0.475  1.103     0.4667    1.27  0.253
O12: C1 -3.7853 11.712 -22.876 19.173     0.6000    2.77  0.376
O12: C2  0.4167  0.635  -0.512  1.415     0.6000    1.82  0.204
O13: C1 -0.2843  9.594 -16.599 17.308     1.0000    1.60  0.183
O13: C2  0.5728  0.488  -0.374  1.456     0.2667    1.58  0.370
O14: C1  0.1892 15.443 -18.735 26.692     0.9333    1.78  0.223
O14: C2  0.3490  0.706  -1.048  1.441     0.6000    1.03  0.183

Posterior summary of the intercepts:
         Mean    SD  2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.333 0.408 -0.32  0.960      0.533    5.29  0.831
O1 > 2 -0.815 0.404 -1.69 -0.235      0.000    2.79  0.519
O1 > 3 -2.139 0.434 -2.93 -1.446      0.000    3.88  0.816


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[12]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C1 * C2 + M2 + O2, data = wideDF, n.adapt = 5, 
    n.iter = 10, nonprop = list(O1 = ~C1 + C2), seed = 2020)


Posterior summary:
           Mean     SD     2.5%  97.5% tail-prob. GR-crit MCE/SD
M22      0.0907  0.495  -0.7010  0.875     0.8667    3.50  0.426
M23      0.0881  0.626  -0.9748  1.138     0.8667    3.66  0.487
M24     -0.2949  0.541  -1.0853  0.638     0.6000    5.12  0.711
O22      0.7608  0.372   0.2336  1.436     0.0000    1.52  0.284
O23      1.2529  0.432   0.4683  1.936     0.0000    2.36  0.217
O24      0.6129  0.332  -0.0292  1.106     0.0667    1.35  0.183
C1:C2    0.3593  1.722  -1.4840  3.534     0.8000   12.04  0.558
O12: C1 -3.3287 13.058 -23.6430 21.644     0.8667    1.99  0.207
O12: C2 -0.1641  2.291  -4.0132  2.821     0.6667   11.12  0.637
O13: C1  3.2186  9.259 -15.0333 18.962     0.7333    1.80  0.183
O13: C2 -0.1565  2.460  -4.9509  2.401     0.8000   10.44  0.857
O14: C1  8.4176 14.225 -19.1953 28.387     0.5333    1.11  0.183
O14: C2 -0.2914  2.392  -4.9768  2.483     0.6667    9.25  0.405

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.357 0.505 -0.252  1.201      0.667    9.74  0.877
O1 > 2 -0.630 0.543 -1.416  0.343      0.333    7.46  0.771
O1 > 3 -1.964 0.559 -2.844 -1.041      0.000    6.27  0.524


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[13]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C1 * C2 + M2 + O2, data = wideDF, n.adapt = 5, 
    n.iter = 10, nonprop = list(O1 = ~C1 * C2), seed = 2020)


Posterior summary:
             Mean     SD     2.5%  97.5% tail-prob. GR-crit MCE/SD
M22        -0.435  0.573  -1.3169  0.802     0.2667    1.57  0.454
M23        -0.360  0.432  -1.0918  0.552     0.3333    1.47  0.220
M24        -0.671  0.381  -1.3104 -0.190     0.0000    1.21  0.218
O22         0.630  0.421   0.0055  1.499     0.0667    1.27  0.183
O23         1.137  0.358   0.5022  1.826     0.0000    2.17  0.215
O24         0.450  0.436  -0.2656  1.210     0.4667    1.83  0.294
O12: C1    -4.640 16.210 -33.3864 24.764     0.7333    1.34  0.183
O12: C2    -1.121  0.936  -2.5518  0.554     0.2667    2.88  0.408
O12: C1:C2  1.053  0.750  -0.2446  2.134     0.0667    2.05  0.331
O13: C1     0.609 11.390 -22.7469 19.125     0.9333    1.76  0.183
O13: C2     0.300  0.567  -0.9403  1.264     0.5333    2.07  0.303
O13: C1:C2  0.139  0.490  -1.0052  0.983     0.4667    2.40  0.417
O14: C1     5.702 18.894 -25.1425 42.809     0.7333    2.53  0.183
O14: C2    -0.357  0.967  -2.1206  1.080     0.8000    1.52  0.522
O14: C1:C2  0.452  0.618  -0.5374  1.692     0.4667    1.73  0.474

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.913 0.395  0.186  1.523        0.0    2.75  0.445
O1 > 2 -0.139 0.462 -1.048  0.513        0.8    2.57  0.474
O1 > 3 -1.497 0.549 -2.510 -0.704        0.0    2.61  0.314


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

[[14]]

Bayesian cumulative logit model fitted with JointAI

Call:
clm_imp(formula = O1 ~ C1 + M2 * C2 + O2, data = wideDF, n.adapt = 5, 
    n.iter = 10, nonprop = list(O1 = ~C1 + C2), seed = 2020)


Posterior summary:
            Mean     SD    2.5%  97.5% tail-prob. GR-crit MCE/SD
M22      0.15112  0.399  -0.610  0.808      0.667    1.36  0.639
M23     -0.00445  0.534  -1.172  0.662      1.000    3.01  0.243
M24     -0.11879  0.472  -0.799  0.681      0.867    1.73  0.272
O22      0.62568  0.691  -0.848  1.565      0.467    4.34  0.399
O23      1.11117  0.629   0.185  2.508      0.000    2.54  0.402
O24      0.24210  0.513  -0.458  1.237      0.733    3.51  0.659
M22:C2  -1.07079  1.173  -3.200  0.660      0.400    1.71  0.216
M23:C2  -0.30506  1.188  -2.835  1.527      0.867    1.82  0.350
M24:C2   1.31880  1.638  -1.794  4.002      0.333    2.28  0.232
O12: C1 -2.08326 15.941 -32.563 23.827      0.933    1.42  0.183
O12: C2  0.34120  1.171  -1.401  2.647      0.933    1.99  0.238
O13: C1 -0.01607  9.945 -20.933 16.984      0.800    1.28  0.183
O13: C2 -0.01960  0.773  -1.254  1.594      0.867    3.46  0.343
O14: C1  2.39260 14.131 -22.112 27.697      0.933    1.63  0.214
O14: C2 -0.12212  0.970  -2.196  1.204      0.867    2.15  0.327

Posterior summary of the intercepts:
         Mean    SD   2.5%  97.5% tail-prob. GR-crit MCE/SD
O1 > 1  0.563 0.508 -0.169  1.489      0.200    5.16  0.701
O1 > 2 -0.534 0.540 -1.192  0.623      0.333    5.13  0.474
O1 > 3 -1.912 0.541 -2.672 -0.989      0.000    5.46  1.078


MCMC settings:
Iterations = 6:15
Sample size per chain = 10 
Thinning interval = 1 
Number of chains = 3 

Number of observations: 100 

